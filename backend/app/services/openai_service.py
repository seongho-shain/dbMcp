"""
OpenAI API ì„œë¹„ìŠ¤
OpenAI GPT ëª¨ë¸ì„ í™œìš©í•œ AI ì‘ë‹µ ìƒì„± ì„œë¹„ìŠ¤
ì±„íŒ… ë©”ì‹œì§€ë¥¼ ë°›ì•„ì„œ AI ì‘ë‹µì„ ìƒì„±í•˜ê³  ë°˜í™˜
"""
import os
import asyncio
from typing import List, Dict, Any, Optional
from fastapi import HTTPException
from openai import OpenAI, AsyncOpenAI
from openai.types.chat import ChatCompletion

from app.config.settings import OPENAI_API_KEY, OPENAI_MODEL


class OpenAIService:
    """
    OpenAI APIë¥¼ í™œìš©í•œ AI ì‘ë‹µ ìƒì„± ì„œë¹„ìŠ¤
    GPT ëª¨ë¸ì„ í†µí•´ ìì—°ìŠ¤ëŸ¬ìš´ ëŒ€í™”í˜• ì‘ë‹µ ì œê³µ
    ë™ê¸° ë° ë¹„ë™ê¸° ëª¨ë“œ ì§€ì›
    """
    
    def __init__(self):
        if not OPENAI_API_KEY:
            raise ValueError("OPENAI_API_KEYê°€ ì„¤ì •ë˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤.")
        
        # OpenAI í´ë¼ì´ì–¸íŠ¸ ì´ˆê¸°í™” (ë™ê¸° ë° ë¹„ë™ê¸°)
        self.client = OpenAI(
            api_key=OPENAI_API_KEY,
            timeout=30.0  # íƒ€ì„ì•„ì›ƒ ì„¤ì •
        )
        self.async_client = AsyncOpenAI(
            api_key=OPENAI_API_KEY,
            timeout=30.0
        )
        self.model = OPENAI_MODEL or "gpt-4o"
    
    def generate_response(self, messages: List[Dict[str, str]], user_context: Optional[Dict[str, Any]] = None) -> str:
        """
        ì‚¬ìš©ì ë©”ì‹œì§€ì— ëŒ€í•œ AI ì‘ë‹µ ìƒì„± (ë™ê¸° ë°©ì‹)
        
        Args:
            messages: ëŒ€í™” íˆìŠ¤í† ë¦¬ (role: user/assistant, content: ë©”ì‹œì§€)
            user_context: ì‚¬ìš©ì ì •ë³´ (ì´ë¦„, ì—­í•  ë“±)
            
        Returns:
            AI ìƒì„± ì‘ë‹µ í…ìŠ¤íŠ¸
            
        Raises:
            HTTPException: OpenAI API í˜¸ì¶œ ì‹¤íŒ¨ ì‹œ
        """
        try:
            # API í‚¤ í™•ì¸
            if not OPENAI_API_KEY:
                print("âŒ OpenAI API í‚¤ê°€ ì„¤ì •ë˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤.")
                raise HTTPException(status_code=500, detail="OpenAI API í‚¤ê°€ ì„¤ì •ë˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤.")
            
            print(f"ğŸ”‘ OpenAI API í‚¤: {OPENAI_API_KEY[:10]}...")
            print(f"ğŸ¤– ì‚¬ìš© ëª¨ë¸: {self.model}")
            
            # ì‹œìŠ¤í…œ ë©”ì‹œì§€ ì„¤ì • (AIì˜ ì—­í• ê³¼ ë§¥ë½ ì •ì˜)
            system_message = self._create_system_message(user_context)
            
            # ì „ì²´ ëŒ€í™” ì»¨í…ìŠ¤íŠ¸ êµ¬ì„±
            full_messages = [system_message] + messages
            
            print(f"ğŸ“ ì „ì†¡í•  ë©”ì‹œì§€ ê°œìˆ˜: {len(full_messages)}")
            for i, msg in enumerate(full_messages):
                print(f"  {i+1}. {msg['role']}: {msg['content'][:50]}...")
            
            # OpenAI API í˜¸ì¶œ (ìµœì‹  íŒ¨í„´ ì ìš©)
            print("ğŸš€ OpenAI API í˜¸ì¶œ ì‹œì‘...")
            completion: ChatCompletion = self.client.chat.completions.create(
                model=self.model,
                messages=full_messages,
                max_tokens=500,
                temperature=0.7,
                presence_penalty=0.1,
                frequency_penalty=0.1,
                stream=False  # ìŠ¤íŠ¸ë¦¬ë° ë¹„í™œì„±í™”
            )
            
            print("âœ… OpenAI API í˜¸ì¶œ ì„±ê³µ!")
            
            # ì•ˆì „í•œ ì‘ë‹µ ì¶”ì¶œ
            if completion.choices and completion.choices[0].message.content:
                response = completion.choices[0].message.content.strip()
                print(f"ğŸ“¤ AI ì‘ë‹µ: {response[:100]}...")
                return response
            else:
                print("âŒ AI ì‘ë‹µì´ ë¹„ì–´ìˆìŠµë‹ˆë‹¤.")
                raise HTTPException(status_code=500, detail="AI ì‘ë‹µì´ ë¹„ì–´ìˆìŠµë‹ˆë‹¤.")
            
        except Exception as e:
            print(f"âŒ OpenAI API ì˜¤ë¥˜: {str(e)}")
            print(f"âŒ ì˜¤ë¥˜ íƒ€ì…: {type(e).__name__}")
            
            # êµ¬ì²´ì ì¸ ì˜¤ë¥˜ ì²˜ë¦¬
            if "rate_limit" in str(e).lower():
                raise HTTPException(status_code=429, detail="API ì‚¬ìš©ëŸ‰ í•œë„ ì´ˆê³¼")
            elif "timeout" in str(e).lower():
                raise HTTPException(status_code=504, detail="API ì‘ë‹µ ì‹œê°„ ì´ˆê³¼")
            elif "invalid_api_key" in str(e).lower():
                raise HTTPException(status_code=401, detail="ìœ íš¨í•˜ì§€ ì•Šì€ API í‚¤")
            else:
                raise HTTPException(status_code=500, detail=f"AI ì‘ë‹µ ìƒì„± ì‹¤íŒ¨: {str(e)}")
    
    async def generate_response_async(self, messages: List[Dict[str, str]], user_context: Optional[Dict[str, Any]] = None) -> str:
        """
        ì‚¬ìš©ì ë©”ì‹œì§€ì— ëŒ€í•œ AI ì‘ë‹µ ìƒì„± (ë¹„ë™ê¸° ë°©ì‹)
        
        Args:
            messages: ëŒ€í™” íˆìŠ¤í† ë¦¬ (role: user/assistant, content: ë©”ì‹œì§€)
            user_context: ì‚¬ìš©ì ì •ë³´ (ì´ë¦„, ì—­í•  ë“±)
            
        Returns:
            AI ìƒì„± ì‘ë‹µ í…ìŠ¤íŠ¸
            
        Raises:
            HTTPException: OpenAI API í˜¸ì¶œ ì‹¤íŒ¨ ì‹œ
        """
        try:
            # ì‹œìŠ¤í…œ ë©”ì‹œì§€ ì„¤ì •
            system_message = self._create_system_message(user_context)
            
            # ì „ì²´ ëŒ€í™” ì»¨í…ìŠ¤íŠ¸ êµ¬ì„±
            full_messages = [system_message] + messages
            
            # ë¹„ë™ê¸° OpenAI API í˜¸ì¶œ
            async with self.async_client:
                completion: ChatCompletion = await self.async_client.chat.completions.create(
                    model=self.model,
                    messages=full_messages,
                    max_tokens=500,
                    temperature=0.7,
                    presence_penalty=0.1,
                    frequency_penalty=0.1,
                    stream=False
                )
            
            # ì•ˆì „í•œ ì‘ë‹µ ì¶”ì¶œ
            if completion.choices and completion.choices[0].message.content:
                return completion.choices[0].message.content.strip()
            else:
                raise HTTPException(status_code=500, detail="AI ì‘ë‹µì´ ë¹„ì–´ìˆìŠµë‹ˆë‹¤.")
            
        except Exception as e:
            # êµ¬ì²´ì ì¸ ì˜¤ë¥˜ ì²˜ë¦¬
            if "rate_limit" in str(e).lower():
                raise HTTPException(status_code=429, detail="API ì‚¬ìš©ëŸ‰ í•œë„ ì´ˆê³¼")
            elif "timeout" in str(e).lower():
                raise HTTPException(status_code=504, detail="API ì‘ë‹µ ì‹œê°„ ì´ˆê³¼")
            else:
                raise HTTPException(status_code=500, detail=f"AI ì‘ë‹µ ìƒì„± ì‹¤íŒ¨: {str(e)}")
    
    def generate_response_stream(self, messages: List[Dict[str, str]], user_context: Optional[Dict[str, Any]] = None):
        """
        ìŠ¤íŠ¸ë¦¬ë° ë°©ì‹ìœ¼ë¡œ AI ì‘ë‹µ ìƒì„±
        
        Args:
            messages: ëŒ€í™” íˆìŠ¤í† ë¦¬
            user_context: ì‚¬ìš©ì ì •ë³´
            
        Yields:
            ìŠ¤íŠ¸ë¦¬ë° ì‘ë‹µ ì²­í¬
        """
        try:
            # ì‹œìŠ¤í…œ ë©”ì‹œì§€ ì„¤ì •
            system_message = self._create_system_message(user_context)
            
            # ì „ì²´ ëŒ€í™” ì»¨í…ìŠ¤íŠ¸ êµ¬ì„±
            full_messages = [system_message] + messages
            
            # ìŠ¤íŠ¸ë¦¬ë° OpenAI API í˜¸ì¶œ
            stream = self.client.chat.completions.create(
                model=self.model,
                messages=full_messages,
                max_tokens=500,
                temperature=0.7,
                presence_penalty=0.1,
                frequency_penalty=0.1,
                stream=True
            )
            
            for chunk in stream:
                if chunk.choices[0].delta.content:
                    yield chunk.choices[0].delta.content
                    
        except Exception as e:
            yield f"ì˜¤ë¥˜: {str(e)}"
    
    def _create_system_message(self, user_context: Optional[Dict[str, Any]] = None) -> Dict[str, str]:
        """
        ì‹œìŠ¤í…œ ë©”ì‹œì§€ ìƒì„± (AIì˜ ì—­í• ê³¼ í–‰ë™ ë°©ì‹ ì •ì˜)
        
        Args:
            user_context: ì‚¬ìš©ì ì •ë³´
            
        Returns:
            ì‹œìŠ¤í…œ ë©”ì‹œì§€ ë”•ì…”ë„ˆë¦¬
        """
        base_prompt = """
        ë‹¹ì‹ ì€ êµìœ¡ìš© AI ì–´ì‹œìŠ¤í„´íŠ¸ì…ë‹ˆë‹¤. 
        ì„ ìƒë‹˜ê³¼ í•™ìƒë“¤ì´ í•¨ê»˜ ì‚¬ìš©í•˜ëŠ” êµìœ¡ í”Œë«í¼ì—ì„œ ë„ì›€ì„ ì œê³µí•©ë‹ˆë‹¤.
        
        ë‹¤ìŒ ì§€ì¹¨ì„ ë”°ë¼ì£¼ì„¸ìš”:
        1. ì¹œê·¼í•˜ê³  ë„ì›€ì´ ë˜ëŠ” í†¤ìœ¼ë¡œ ëŒ€í™”í•˜ì„¸ìš”
        2. êµìœ¡ì  ê°€ì¹˜ê°€ ìˆëŠ” ë‹µë³€ì„ ì œê³µí•˜ì„¸ìš”
        3. í•™ìŠµì— ë„ì›€ì´ ë˜ëŠ” ì§ˆë¬¸ì´ë‚˜ ì„¤ëª…ì„ í•´ì£¼ì„¸ìš”
        4. ë¶€ì ì ˆí•œ ë‚´ìš©ì€ ì •ì¤‘íˆ ê±°ì ˆí•˜ì„¸ìš”
        5. í•œêµ­ì–´ë¡œ ë‹µë³€í•´ì£¼ì„¸ìš”
        """
        
        if user_context:
            user_type = user_context.get('user_type', 'student')
            user_name = user_context.get('user_name', 'ì‚¬ìš©ì')
            
            if user_type == 'teacher':
                base_prompt += f"""
                
                í˜„ì¬ ëŒ€í™” ìƒëŒ€ëŠ” {user_name} ì„ ìƒë‹˜ì…ë‹ˆë‹¤.
                ì„ ìƒë‹˜ì˜ ìˆ˜ì—… ì¤€ë¹„ë‚˜ í•™ìƒ ê´€ë¦¬ì— ë„ì›€ì´ ë˜ëŠ” ì¡°ì–¸ì„ ì œê³µí•˜ì„¸ìš”.
                """
            else:
                base_prompt += f"""
                
                í˜„ì¬ ëŒ€í™” ìƒëŒ€ëŠ” {user_name} í•™ìƒì…ë‹ˆë‹¤.
                í•™ìŠµì— ë„ì›€ì´ ë˜ëŠ” ì¹œê·¼í•œ ì„¤ëª…ê³¼ ê²©ë ¤ë¥¼ ì œê³µí•˜ì„¸ìš”.
                """
        
        return {"role": "system", "content": base_prompt}
    
    def generate_educational_response(self, question: str, subject: Optional[str] = None, level: Optional[str] = None) -> str:
        """
        êµìœ¡ì  ì§ˆë¬¸ì— ëŒ€í•œ íŠ¹í™”ëœ ì‘ë‹µ ìƒì„±
        
        Args:
            question: êµìœ¡ ê´€ë ¨ ì§ˆë¬¸
            subject: ê³¼ëª© (ì„ íƒì‚¬í•­)
            level: í•™ìŠµ ìˆ˜ì¤€ (ì„ íƒì‚¬í•­)
            
        Returns:
            êµìœ¡ì  AI ì‘ë‹µ
        """
        messages = [
            {
                "role": "user",
                "content": f"ì§ˆë¬¸: {question}" + 
                          (f"\nê³¼ëª©: {subject}" if subject else "") +
                          (f"\nìˆ˜ì¤€: {level}" if level else "")
            }
        ]
        
        return self.generate_response(messages)
    
    def __enter__(self):
        """ì»¨í…ìŠ¤íŠ¸ ë§¤ë‹ˆì € ì§„ì…"""
        return self
    
    def __exit__(self, exc_type, exc_val, exc_tb):
        """ì»¨í…ìŠ¤íŠ¸ ë§¤ë‹ˆì € ì¢…ë£Œ - ë¦¬ì†ŒìŠ¤ ì •ë¦¬"""
        if hasattr(self.client, 'close'):
            self.client.close()
        if hasattr(self.async_client, 'close'):
            asyncio.create_task(self.async_client.close())